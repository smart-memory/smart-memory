# ===== PROMPTS (smartmemory) =====
# Host path for local runs
SMARTMEMORY_PROMPTS=smart-memory/smartmemory/prompts.json
# Auto-start Mongo-backed overrides sync inside processes using smartmemory
PROMPTS_OVERRIDES_AUTO_START=true
# Default workspace identifier for the overrides document
PROMPTS_OVERRIDES_WORKSPACE_ID=default

# ===== GLOBAL CONFIGURATION =====
# Python
PYTHONPATH=/app

# Docker
DOCKER_COMPOSE_VERSION=3.8
RESTART_POLICY=unless-stopped
VOLUME_DRIVER=local

# Network
SMARTMEMORY_NETWORK=smartmemory-network
NETWORK_DRIVER=bridge
SMARTMEMORY_DEV_NETWORK=smartmemory-dev-network
SMARTMEMORY_DEV_NETWORK_NAME=smartmemory-dev-network

# Development
DEV_WORKING_DIR=/app
PYCACHE_EXCLUDE=/app/__pycache__
PYTEST_CACHE_EXCLUDE=/app/.pytest_cache
NODE_MODULES_EXCLUDE=/app/node_modules

SMARTMEMORY_CONFIG=config.json

# ===== FALKORDB SERVICE =====
# Unified port configuration
FALKORDB_PORT=9010
FALKORDB_HOST=localhost
FALKORDB_WEB_PORT=3000
FALKORDB_ARGS=--port 9010 --bind 0.0.0.0 --protected-mode no
FALKORDB_VOLUME_DATA=falkordb_data
FALKORDB_VOLUME_TARGET=/data

# ===== REDIS SERVICE =====
# Unified port configuration
REDIS_PORT=9012
REDIS_HOST=localhost
REDIS_MAXMEMORY=256mb
REDIS_MAXMEMORY_POLICY=allkeys-lru
REDIS_VOLUME_DATA=redis_data
REDIS_VOLUME_TARGET=/data

# ===== EMBEDDING PROVIDERS =====
# Choose provider: openai, ollama, or huggingface
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-ada-002

# OpenAI
OPENAI_API_KEY=

# HuggingFace (optional - for API-based inference)
HUGGINGFACE_API_KEY=
# HuggingFace model (for both API and local inference)
# Popular options: sentence-transformers/all-MiniLM-L6-v2, sentence-transformers/all-mpnet-base-v2
HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Ollama (for local inference)
OLLAMA_URL=http://localhost:11434

